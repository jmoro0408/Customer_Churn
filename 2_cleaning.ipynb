{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) # Display all columns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fname = Path(\"dataset.csv\")\n",
    "df = pd.read_csv(input_fname, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tran Test Split\n",
    "Before I undertake any data cleaning or transformation I'll put aside a test set for final model performance. \n",
    "I intend to use cross validation during training to evaluate the model iteratively, so don't need to set aside a validation set at this point. \n",
    "\n",
    "Due to the high imbalance present in the target feature, seen in the previous notebook, it is important the train test split is stratified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_pos_prior = 100*(df['CHURN'].value_counts()[1] / len(df)) # % positive target feature prior to splitting\n",
    "perc_pos_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('CHURN', axis = 1)\n",
    "y = df['CHURN']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y) # 80:20 train:test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of positive target features in y_train: 0.67 %\n",
      "% of positive target features in y_train: 0.67 %\n"
     ]
    }
   ],
   "source": [
    "y_train_unique, y_train_counts = np.unique(y_train, return_counts=True)\n",
    "y_test_unique, y_test_counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "perc_pos_post_train = y_train_counts[1]/ (sum(y_train_counts)) * 100\n",
    "perc_pos_post_test = y_train_counts[1]/ (sum(y_train_counts)) * 100\n",
    "\n",
    "print(f\"% of positive target features in y_train: {perc_pos_post_train } %\")\n",
    "print(f\"% of positive target features in y_train: {perc_pos_post_test} %\")\n",
    "\n",
    "assert np.isclose(a = perc_pos_post_train,b =  perc_pos_prior)\n",
    "assert np.isclose(a = perc_pos_post_test,b =  perc_pos_prior)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a stratified train test split we can put aside the test set for future use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
